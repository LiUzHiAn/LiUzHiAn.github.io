<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="一个记录关于生活,计算机,成长,旅行的地方">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
          目标检测——SSD源码解读 - 刘知安的博客 | LiuZhian&#39;s Blog
        
    </title>

    <link rel="canonical" href="https://liuzhian.github.io/2019/11/19/目标检测-SSD源码解读/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/hux-blog.min.css">


    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">LiuZhian&#39;s Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">主页</a>
                    </li>

                    

                        
                    

                        
                    

                        
                        <li>
                            <a href="/about/">关于我</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archives/">随笔</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">归类</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    

<!-- Image to hack wechat -->
<!-- <img src="https://liuzhian.github.io/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="{{ site.baseurl }}/{% if page.header-img %}{{ page.header-img }}{% else %}{{ site.header-img }}{% endif %}" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        background-image: url('head-img.jpg')
    }
</style>
<header class="intro-header" >
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                          <a class="tag" href="/tags/#Object Detection" title="Object Detection">Object Detection</a>
                        
                    </div>
                    <h1>目标检测——SSD源码解读</h1>
                    <h2 class="subheading">目标检测经典方法</h2>
                    <span class="meta">
                        Posted by 刘知安 on
                        2019-11-19
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">
				
				<!-- 文章目录全局默认开启，如果不加目录，在文章front-matter设置toc为false -->  
				
				<div id="toc" class="toc-article">
				
                    <strong class="toc-title">文章目录</strong>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#0-简介"><span class="toc-text">0.简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-代码解析"><span class="toc-text">1.代码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-项目结构分析"><span class="toc-text">1.1 项目结构分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-源码"><span class="toc-text">1.2 源码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-SSD网络结构定义"><span class="toc-text">1.2.1 SSD网络结构定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-default-boxes定义"><span class="toc-text">1.2.2 default boxes定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-训练"><span class="toc-text">1.2.2 训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-3-测试"><span class="toc-text">1.2.3 测试</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-遇到的问题"><span class="toc-text">2.遇到的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-维度不匹配"><span class="toc-text">2.1 维度不匹配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-取0维tensor值出错"><span class="toc-text">2.2 取0维tensor值出错</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-不需要求导的变量"><span class="toc-text">2.3 不需要求导的变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-Xavier初始化函数"><span class="toc-text">2.4 Xavier初始化函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-F-smooth-l1-loss"><span class="toc-text">2.5 F.smooth_l1_loss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-6-visdom画图报错"><span class="toc-text">2.6 visdom画图报错</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-7-一轮过后取batch报错"><span class="toc-text">2.7 一轮过后取batch报错</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-模型的运用"><span class="toc-text">3.模型的运用</span></a></li></ol>
                    
                    <!-- 文章目录用的是themes\huxblog\source\css下的post.style,hexo会把它生成一个post.css文件在public文件夹中 -->
                    
<link rel="stylesheet" href="/css/post.css">

				
                </div>
				
				
                <h1 id="0-简介"><a href="#0-简介" class="headerlink" title="0.简介"></a>0.简介</h1><p><code>SSD</code>的全称是<code>Single Shot MultiBox Detector</code>，是目标检测中经典方法之一，它和<code>YOLO</code>一样，都是one-stage模式的，而像<code>R-CNN</code>和<code>Fast R-CNN</code>这些文章则是two-stage的，也就是需要先提取出proposals，再对各个proposal进行定位和分类。</p>
<p>接下来，我将尽我所能，结合自身理解和网上的一些参考资料，对Pytorch版本的SSD源码进行解析，代码仓库的地址是<a href="https://github.com/amdegroot/ssd.pytorch" target="_blank" rel="noopener">SSD-Pytorch</a>,我将按照代码的执行顺序，并结合论文，自顶向下地进行分析，请务必细读论文。</p>
<h1 id="1-代码解析"><a href="#1-代码解析" class="headerlink" title="1.代码解析"></a>1.代码解析</h1><h2 id="1-1-项目结构分析"><a href="#1-1-项目结构分析" class="headerlink" title="1.1 项目结构分析"></a>1.1 项目结构分析</h2><p>在解析代码之前，我们很有必要先熟悉项目代码的组织结构，以下是项目的目录结构：<br><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">eval.py 	<span class="comment"># evaluation</span></span><br><span class="line">ssd.py		<span class="comment"># ssd模型定义部分</span></span><br><span class="line">train.py	<span class="comment"># 训练</span></span><br><span class="line">test.py		<span class="comment"># 测试</span></span><br><span class="line"><span class="string">/data</span>	<span class="comment"># 存放数据集的目录</span></span><br><span class="line">	<span class="string">/script</span>	<span class="comment"># 下载数据集的脚本</span></span><br><span class="line">		COCO2014.sh <span class="comment"># 下载COCO2014的脚本</span></span><br><span class="line">		VOC2017.sh <span class="comment"># 下载PASCAL VOC 2017的脚本</span></span><br><span class="line">		VOC2012.sh <span class="comment"># 下载PASCAL VOC 2012的脚本</span></span><br><span class="line"></span><br><span class="line"><span class="string">/demo</span>	<span class="comment"># 演示代码</span></span><br><span class="line"></span><br><span class="line"><span class="string">/layers</span>	<span class="comment"># 网络层中需要用到的代码</span></span><br><span class="line">	__init__.py </span><br><span class="line">	box_utils.py <span class="comment"># 变换box坐标的一些函数</span></span><br><span class="line">	<span class="string">/functions</span>	<span class="comment"># 一些辅助函数</span></span><br><span class="line">		__init__.py</span><br><span class="line">		detection.py <span class="comment"># 将模型输出转化为的box的辅助模块</span></span><br><span class="line">		prior_box.py <span class="comment"># 定义prior box （即default box）的辅助模块</span></span><br><span class="line">	<span class="string">/moudules</span> <span class="comment"># 损失函数模块</span></span><br><span class="line">		__init__.py</span><br><span class="line">		l2norm.py	<span class="comment"># 2范数</span></span><br><span class="line">		multibox_loss.py <span class="comment"># multibox_loss损失函数</span></span><br><span class="line">		</span><br><span class="line"><span class="string">/utils</span> <span class="comment"># 辅助模块目录</span></span><br><span class="line">	__init__.py</span><br><span class="line">	augmentation.py <span class="comment"># 数据增广辅助模块</span></span><br><span class="line"></span><br><span class="line"><span class="string">/weights</span> <span class="comment"># 存放模型weight的目录</span></span><br></pre></td></tr></table></figure></p>
<h2 id="1-2-源码"><a href="#1-2-源码" class="headerlink" title="1.2 源码"></a>1.2 源码</h2><h3 id="1-2-1-SSD网络结构定义"><a href="#1-2-1-SSD网络结构定义" class="headerlink" title="1.2.1 SSD网络结构定义"></a>1.2.1 SSD网络结构定义</h3><p>首先从<code>train.py</code>中的<code>train()</code>函数入口开始分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> data.voc0712 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> utils.augmentations <span class="keyword">import</span> SSDAugmentation</span><br><span class="line"><span class="keyword">from</span> layers.modules <span class="keyword">import</span> MultiBoxLoss</span><br><span class="line"><span class="keyword">from</span> ssd <span class="keyword">import</span> build_ssd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"><span class="keyword">import</span> torch.nn.init <span class="keyword">as</span> init</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> data <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">str2bool</span><span class="params">(v)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> v.lower() <span class="keyword">in</span> (<span class="string">"yes"</span>, <span class="string">"true"</span>, <span class="string">"t"</span>, <span class="string">"1"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(</span><br><span class="line">    description=<span class="string">'Single Shot MultiBox Detector Training With Pytorch'</span>)</span><br><span class="line">train_set = parser.add_mutually_exclusive_group()</span><br><span class="line">parser.add_argument(<span class="string">'--dataset'</span>, default=<span class="string">'VOC'</span>, choices=[<span class="string">'VOC'</span>, <span class="string">'COCO'</span>],</span><br><span class="line">                    type=str, help=<span class="string">'VOC or COCO'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--dataset_root'</span>, default=VOC_ROOT,</span><br><span class="line">                    help=<span class="string">'Dataset root directory path'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--basenet'</span>, default=<span class="string">'vgg16_reducedfc.pth'</span>,</span><br><span class="line">                    help=<span class="string">'Pretrained base model'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--batch_size'</span>, default=<span class="number">32</span>, type=int,</span><br><span class="line">                    help=<span class="string">'Batch size for training'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--resume'</span>, default=<span class="literal">None</span>, type=str,</span><br><span class="line">                    help=<span class="string">'Checkpoint state_dict file to resume training from'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--start_iter'</span>, default=<span class="number">0</span>, type=int,</span><br><span class="line">                    help=<span class="string">'Resume training at this iter'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--num_workers'</span>, default=<span class="number">4</span>, type=int,</span><br><span class="line">                    help=<span class="string">'Number of workers used in dataloading'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--cuda'</span>, default=<span class="literal">True</span>, type=str2bool,</span><br><span class="line">                    help=<span class="string">'Use CUDA to train model'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--lr'</span>, <span class="string">'--learning-rate'</span>, default=<span class="number">1e-3</span>, type=float,</span><br><span class="line">                    help=<span class="string">'initial learning rate'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--momentum'</span>, default=<span class="number">0.9</span>, type=float,</span><br><span class="line">                    help=<span class="string">'Momentum value for optim'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--weight_decay'</span>, default=<span class="number">5e-4</span>, type=float,</span><br><span class="line">                    help=<span class="string">'Weight decay for SGD'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--gamma'</span>, default=<span class="number">0.1</span>, type=float,</span><br><span class="line">                    help=<span class="string">'Gamma update for SGD'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--visdom'</span>, default=<span class="literal">True</span>, type=str2bool,</span><br><span class="line">                    help=<span class="string">'Use visdom for loss visualization'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--save_folder'</span>, default=<span class="string">'weights/'</span>,</span><br><span class="line">                    help=<span class="string">'Directory for saving checkpoint models'</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    <span class="keyword">if</span> args.cuda:</span><br><span class="line">        torch.set_default_tensor_type(<span class="string">'torch.cuda.FloatTensor'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> args.cuda:</span><br><span class="line">        print(<span class="string">"WARNING: It looks like you have a CUDA device, but aren't "</span> +</span><br><span class="line">              <span class="string">"using CUDA.\nRun with --cuda for optimal training speed."</span>)</span><br><span class="line">        torch.set_default_tensor_type(<span class="string">'torch.FloatTensor'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    torch.set_default_tensor_type(<span class="string">'torch.FloatTensor'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.save_folder):</span><br><span class="line">    os.mkdir(args.save_folder)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">if</span> args.dataset == <span class="string">'COCO'</span>:</span><br><span class="line">        <span class="keyword">if</span> args.dataset_root == VOC_ROOT:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(COCO_ROOT):</span><br><span class="line">                parser.error(<span class="string">'Must specify dataset_root if specifying dataset'</span>)</span><br><span class="line">            print(<span class="string">"WARNING: Using default COCO dataset_root because "</span> +</span><br><span class="line">                  <span class="string">"--dataset_root was not specified."</span>)</span><br><span class="line">            args.dataset_root = COCO_ROOT</span><br><span class="line">        cfg = coco</span><br><span class="line">        dataset = COCODetection(root=args.dataset_root,</span><br><span class="line">                                transform=SSDAugmentation(cfg[<span class="string">'min_dim'</span>],</span><br><span class="line">                                                          MEANS))</span><br><span class="line">    <span class="keyword">elif</span> args.dataset == <span class="string">'VOC'</span>:</span><br><span class="line">        <span class="keyword">if</span> args.dataset_root == COCO_ROOT:</span><br><span class="line">            parser.error(<span class="string">'Must specify dataset if specifying dataset_root'</span>)</span><br><span class="line">        cfg = voc</span><br><span class="line">        dataset = VOCDetection(root=args.dataset_root,</span><br><span class="line">                               transform=SSDAugmentation(cfg[<span class="string">'min_dim'</span>],</span><br><span class="line">                                                         MEANS))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.visdom:</span><br><span class="line">        <span class="keyword">import</span> visdom</span><br><span class="line">        viz = visdom.Visdom()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建一个SSD网络</span></span><br><span class="line">    ssd_net = build_ssd(<span class="string">'train'</span>, cfg[<span class="string">'min_dim'</span>], cfg[<span class="string">'num_classes'</span>])</span><br><span class="line">    net = ssd_net</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.cuda:</span><br><span class="line">        net = torch.nn.DataParallel(ssd_net)</span><br><span class="line">        cudnn.benchmark = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.resume:</span><br><span class="line">        print(<span class="string">'Resuming training, loading &#123;&#125;...'</span>.format(args.resume))</span><br><span class="line">        ssd_net.load_weights(args.resume)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        vgg_weights = torch.load(args.save_folder + args.basenet)</span><br><span class="line">        print(<span class="string">'Loading base network...'</span>)</span><br><span class="line">        ssd_net.vgg.load_state_dict(vgg_weights)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.cuda:</span><br><span class="line">        net = net.cuda()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> args.resume:</span><br><span class="line">        print(<span class="string">'Initializing weights...'</span>)</span><br><span class="line">        <span class="comment"># initialize newly added layers' weights with xavier method</span></span><br><span class="line">        ssd_net.extras.apply(weights_init)</span><br><span class="line">        ssd_net.loc.apply(weights_init)</span><br><span class="line">        ssd_net.conf.apply(weights_init)</span><br><span class="line"></span><br><span class="line">    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,</span><br><span class="line">                          weight_decay=args.weight_decay)</span><br><span class="line">    criterion = MultiBoxLoss(cfg[<span class="string">'num_classes'</span>], <span class="number">0.5</span>, <span class="literal">True</span>, <span class="number">0</span>, <span class="literal">True</span>, <span class="number">3</span>, <span class="number">0.5</span>,</span><br><span class="line">                             <span class="literal">False</span>, args.cuda)</span><br><span class="line"></span><br><span class="line">    net.train()</span><br><span class="line">    <span class="comment"># loss counters</span></span><br><span class="line">    loc_loss = <span class="number">0</span></span><br><span class="line">    conf_loss = <span class="number">0</span></span><br><span class="line">    epoch = <span class="number">0</span></span><br><span class="line">    print(<span class="string">'Loading the dataset...'</span>)</span><br><span class="line"></span><br><span class="line">    epoch_size = len(dataset) // args.batch_size</span><br><span class="line">    print(<span class="string">'Training SSD on:'</span>, dataset.name)</span><br><span class="line">    print(<span class="string">'Using the specified args:'</span>)</span><br><span class="line">    print(args)</span><br><span class="line"></span><br><span class="line">    step_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.visdom:</span><br><span class="line">        vis_title = <span class="string">'SSD.PyTorch on '</span> + dataset.name</span><br><span class="line">        vis_legend = [<span class="string">'Loc Loss'</span>, <span class="string">'Conf Loss'</span>, <span class="string">'Total Loss'</span>]</span><br><span class="line">        iter_plot = create_vis_plot(<span class="string">'Iteration'</span>, <span class="string">'Loss'</span>, vis_title, vis_legend)</span><br><span class="line">        epoch_plot = create_vis_plot(<span class="string">'Epoch'</span>, <span class="string">'Loss'</span>, vis_title, vis_legend)</span><br><span class="line"></span><br><span class="line">    data_loader = data.DataLoader(dataset, args.batch_size,</span><br><span class="line">                                  num_workers=args.num_workers,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>, collate_fn=detection_collate,</span><br><span class="line">                                  pin_memory=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># create batch iterator</span></span><br><span class="line">    batch_iterator = iter(data_loader)</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(args.start_iter, cfg[<span class="string">'max_iter'</span>]):</span><br><span class="line">        <span class="keyword">if</span> args.visdom <span class="keyword">and</span> iteration != <span class="number">0</span> <span class="keyword">and</span> (iteration % epoch_size == <span class="number">0</span>):</span><br><span class="line">            update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, <span class="literal">None</span>,</span><br><span class="line">                            <span class="string">'append'</span>, epoch_size)</span><br><span class="line">            <span class="comment"># reset epoch loss counters</span></span><br><span class="line">            loc_loss = <span class="number">0</span></span><br><span class="line">            conf_loss = <span class="number">0</span></span><br><span class="line">            epoch += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iteration <span class="keyword">in</span> cfg[<span class="string">'lr_steps'</span>]:</span><br><span class="line">            step_index += <span class="number">1</span></span><br><span class="line">            adjust_learning_rate(optimizer, args.gamma, step_index)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># load train data</span></span><br><span class="line">        images, targets = next(batch_iterator)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> args.cuda:</span><br><span class="line">            images = Variable(images.cuda())</span><br><span class="line">            targets = [Variable(ann.cuda(), volatile=<span class="literal">True</span>) <span class="keyword">for</span> ann <span class="keyword">in</span> targets]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            images = Variable(images)</span><br><span class="line">            targets = [Variable(ann, volatile=<span class="literal">True</span>) <span class="keyword">for</span> ann <span class="keyword">in</span> targets]</span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        t0 = time.time()</span><br><span class="line">        out = net(images)</span><br><span class="line">        <span class="comment"># backprop</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss_l, loss_c = criterion(out, targets)</span><br><span class="line">        loss = loss_l + loss_c</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        t1 = time.time()</span><br><span class="line">        loc_loss += loss_l.data[<span class="number">0</span>]</span><br><span class="line">        conf_loss += loss_c.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'timer: %.4f sec.'</span> % (t1 - t0))</span><br><span class="line">            print(<span class="string">'iter '</span> + repr(iteration) + <span class="string">' || Loss: %.4f ||'</span> % (loss.data[<span class="number">0</span>]), end=<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> args.visdom:</span><br><span class="line">            update_vis_plot(iteration, loss_l.data[<span class="number">0</span>], loss_c.data[<span class="number">0</span>],</span><br><span class="line">                            iter_plot, epoch_plot, <span class="string">'append'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iteration != <span class="number">0</span> <span class="keyword">and</span> iteration % <span class="number">5000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Saving state, iter:'</span>, iteration)</span><br><span class="line">            torch.save(ssd_net.state_dict(), <span class="string">'weights/ssd300_COCO_'</span> +</span><br><span class="line">                       repr(iteration) + <span class="string">'.pth'</span>)</span><br><span class="line">    torch.save(ssd_net.state_dict(),</span><br><span class="line">               args.save_folder + <span class="string">''</span> + args.dataset + <span class="string">'.pth'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adjust_learning_rate</span><span class="params">(optimizer, gamma, step)</span>:</span></span><br><span class="line">    <span class="string">"""Sets the learning rate to the initial LR decayed by 10 at every</span></span><br><span class="line"><span class="string">        specified step</span></span><br><span class="line"><span class="string">    # Adapted from PyTorch Imagenet example:</span></span><br><span class="line"><span class="string">    # https://github.com/pytorch/examples/blob/master/imagenet/main.py</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    lr = args.lr * (gamma ** (step))</span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">'lr'</span>] = lr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xavier</span><span class="params">(param)</span>:</span></span><br><span class="line">    init.xavier_uniform(param)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init</span><span class="params">(m)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">        xavier(m.weight.data)</span><br><span class="line">        m.bias.data.zero_()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_vis_plot</span><span class="params">(_xlabel, _ylabel, _title, _legend)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> viz.line(</span><br><span class="line">        X=torch.zeros((<span class="number">1</span>,)).cpu(),</span><br><span class="line">        Y=torch.zeros((<span class="number">1</span>, <span class="number">3</span>)).cpu(),</span><br><span class="line">        opts=dict(</span><br><span class="line">            xlabel=_xlabel,</span><br><span class="line">            ylabel=_ylabel,</span><br><span class="line">            title=_title,</span><br><span class="line">            legend=_legend</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_vis_plot</span><span class="params">(iteration, loc, conf, window1, window2, update_type,</span></span></span><br><span class="line"><span class="function"><span class="params">                    epoch_size=<span class="number">1</span>)</span>:</span></span><br><span class="line">    viz.line(</span><br><span class="line">        X=torch.ones((<span class="number">1</span>, <span class="number">3</span>)).cpu() * iteration,</span><br><span class="line">        Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(<span class="number">0</span>).cpu() / epoch_size,</span><br><span class="line">        win=window1,</span><br><span class="line">        update=update_type</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># initialize epoch plot on first iteration</span></span><br><span class="line">    <span class="keyword">if</span> iteration == <span class="number">0</span>:</span><br><span class="line">        viz.line(</span><br><span class="line">            X=torch.zeros((<span class="number">1</span>, <span class="number">3</span>)).cpu(),</span><br><span class="line">            Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(<span class="number">0</span>).cpu(),</span><br><span class="line">            win=window2,</span><br><span class="line">            update=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    train()</span><br></pre></td></tr></table></figure></p>
<p>那些命令行参数可以暂且不看，当然，这些参数也很常见。<code>train()</code>函数的第97行<code>ssd_net = build_ssd(&#39;train&#39;, cfg[&#39;min_dim&#39;], cfg[&#39;num_classes&#39;])</code>，build一个SSD模型。而<code>build_ssd()</code>函数的定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_ssd</span><span class="params">(phase, size=<span class="number">300</span>, num_classes=<span class="number">21</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> phase != <span class="string">"test"</span> <span class="keyword">and</span> phase != <span class="string">"train"</span>:</span><br><span class="line">        print(<span class="string">"ERROR: Phase: "</span> + phase + <span class="string">" not recognized"</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> size != <span class="number">300</span>:</span><br><span class="line">        print(<span class="string">"ERROR: You specified size "</span> + repr(size) + <span class="string">". However, "</span> +</span><br><span class="line">              <span class="string">"currently only SSD300 (size=300) is supported!"</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    base_, extras_, head_ = multibox(vgg(base[str(size)], <span class="number">3</span>),</span><br><span class="line">                     add_extras(extras[str(size)], <span class="number">1024</span>),</span><br><span class="line">                     mbox[str(size)],</span><br><span class="line">                     num_classes)</span><br><span class="line">    <span class="keyword">return</span> SSD(phase, size, base_, extras_, head_, num_classes)</span><br></pre></td></tr></table></figure>
<p>第一个参数是用来标定是训练还是测试过程，第二个size是SSD输入的分辨率，SSD-300模型的输入就是300，num_classes是所有目标的类别数+背景，我们这里用的是VOC dataset，所以物体共有20类，所以一共是21。可以看到，该函数中又调用了<code>multibox()</code>函数具体负责搭建模型工作.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">base_, extras_, head_ = multibox(vgg(base[str(size)], <span class="number">3</span>),</span><br><span class="line">				 add_extras(extras[str(size)], <span class="number">1024</span>),</span><br><span class="line">				 mbox[str(size)],</span><br><span class="line">				 num_classes)</span><br></pre></td></tr></table></figure><br>因为论文中明确说到，SSD的base network用的是VGG，更具体点说，SSD-300用的base network是VGG-16,SSD的整体架构如下所示：</p>
<p><img src="architecture.jpg" alt="SSD-300架构图"></p>
<p>而VGG网络具体的building block参见下图：</p>
<p><img src="VGG.png" alt="VGG各模块"></p>
<p>所以<code>multibox()</code>函数的前2个参数分别是VGG-16和Extra网络部分，而第3个参数是指明多个层输出中，即multi-box部分，每个feature map上的每个location输出几个default box。所以我们下面先分析一下VGG和Extra网络部分的具体结构啦。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This function is derived from torchvision VGG make_layers()</span></span><br><span class="line"><span class="comment"># https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span><span class="params">(cfg, i, batch_norm=False)</span>:</span></span><br><span class="line">    <span class="comment"># cfg 是  [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M', 512, 512, 512],</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = i</span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">'M'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="comment"># When ceil_mode True, will use ceil instead of floor to compute the output shape</span></span><br><span class="line">        <span class="keyword">elif</span> v == <span class="string">'C'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 参见论文第3部分开头，</span></span><br><span class="line">    <span class="comment"># change pool5 from 2*2-s2 to 3*3-s1</span></span><br><span class="line">    <span class="comment"># convert vgg fc6 &amp; fc7 to conv layers</span></span><br><span class="line">    <span class="comment"># and use atrous algorithm to fill the "hole"</span></span><br><span class="line">    pool5 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">    conv6 = nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">6</span>, dilation=<span class="number">6</span>)</span><br><span class="line">    conv7 = nn.Conv2d(<span class="number">1024</span>, <span class="number">1024</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">    layers += [pool5, conv6,</span><br><span class="line">               nn.ReLU(inplace=<span class="literal">True</span>), conv7, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">    <span class="keyword">return</span> layers</span><br></pre></td></tr></table></figure>
<p>上面的代码就照葫芦画瓢搭建出来即可，这里代码看上去有点不是很直观，当然，我们可以自己一层一层的写，不要任何循环，那样代码的通用性就差了些，稍微看下这个代码也是可以很快看明白的。不过我们要注意SSD-300的base network还是和VGG-16有一定的差别的，在论文的第3部分的Base network小节有具体描述，它们是：</p>
<ul>
<li>把VGG-16的fc6和fc7全部换成卷积层</li>
<li>把VGG-16的 2x2-stride-2换成了 3x3-stride-1</li>
<li>在conv6层中运用了空洞卷积，以扩大感受野</li>
<li>丢掉了所有的dropout层和fc8</li>
</ul>
<p>而Extra 网络部分的代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_extras</span><span class="params">(cfg, i, batch_norm=False)</span>:</span></span><br><span class="line">    <span class="comment"># Extra layers added to VGG for feature scaling</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = i</span><br><span class="line">    flag = <span class="literal">False</span>  <span class="comment"># 是否用3*3 conv的标志</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> enumerate(cfg):</span><br><span class="line">        <span class="keyword">if</span> in_channels != <span class="string">'S'</span>:</span><br><span class="line">            <span class="keyword">if</span> v == <span class="string">'S'</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels, cfg[k + <span class="number">1</span>], kernel_size=(<span class="number">1</span>, <span class="number">3</span>)[flag], stride=<span class="number">2</span>, padding=<span class="number">1</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels, v, kernel_size=(<span class="number">1</span>, <span class="number">3</span>)[flag])]</span><br><span class="line">            flag = <span class="keyword">not</span> flag</span><br><span class="line">        in_channels = v</span><br><span class="line">    <span class="keyword">return</span> layers</span><br></pre></td></tr></table></figure><br>同样，这些代码看上去一时半会还不好看懂，反正按照论文中的架构build出来即可。<br>Okay，现在我们把VGG部分和Extra部分都搭建好了，传给<code>multibox(vgg, extra_layers, cfg, num_classes)</code>函数总和起来即可，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multibox</span><span class="params">(vgg, extra_layers, cfg, num_classes)</span>:</span></span><br><span class="line">    loc_layers = []</span><br><span class="line">    conf_layers = []</span><br><span class="line">    vgg_source = [<span class="number">21</span>, <span class="number">-2</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> enumerate(vgg_source):</span><br><span class="line">	    loc_layers += [nn.Conv2d(vgg[v].out_channels,</span><br><span class="line">				     cfg[k] * <span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">	    conf_layers += [nn.Conv2d(vgg[v].out_channels,</span><br><span class="line">				      cfg[k] * num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> enumerate(extra_layers[<span class="number">1</span>::<span class="number">2</span>], <span class="number">2</span>):</span><br><span class="line">	    loc_layers += [nn.Conv2d(v.out_channels, cfg[k]</span><br><span class="line">				     * <span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">	    conf_layers += [nn.Conv2d(v.out_channels, cfg[k]</span><br><span class="line">				      * num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">return</span> vgg, extra_layers, (loc_layers, conf_layers)</span><br></pre></td></tr></table></figure><br>这里稍微注意一下，SSD中采用了Multi Box思想，也就是说，在网络中不同阶段都输出一定数量的box，因为不同阶段的scale是不同的，在网络的前面输出小物体可能更精确，而网络偏后面部分输出大物体会更精确一些。具体来说，论文中选用了<code>VGG的Conv4_3</code>,<code>Conv7(即VGG的FC7位置)</code>,<code>Conv8_2</code>,<code>Conv9_2</code>,<code>Conv10_2</code>,<code>Conv11_2</code>这6个地方的feature maps，每个feature maps的每个location分别对应输出<code>4, 6, 6, 6, 4, 4</code>个default box。举例来说，比如<code>VGG的Conv4_3</code>层的输出feature maps的大小是38x38，那么每个像素点都会输出4个defalut box，于是一共输出38x38x4个default boxes。</p>
<p>综合上述的6层，输入一张图片，会输出<code>38*38*4 + 19*19*6 + 10*10*6 + 5*5*6 + 3*3*4 + 1*1*4 = 8732</code>个预选框。</p>
<p>这里有个trick需要注意一下，就是在<code>Conv4_3</code>层的L2 normalize，论文中3.1部分如下表述到：</p>
<blockquote>
<p>Since, as pointed out in [12], conv4 3 has a different feature scale compared to the other layers, we use the L2 normalization technique introduced in [12] to scale the feature norm at each location in the feature map to 20 and learn the scale during back propagation.</p>
</blockquote>
<p>代码中<code>layers/modules/l2norm.py</code>有这样一个归一化层，不过现在Pytorch已经支持了这个API。有了上述部分，我们终于可以build出来SSD了。</p>
<h3 id="1-2-2-default-boxes定义"><a href="#1-2-2-default-boxes定义" class="headerlink" title="1.2.2 default boxes定义"></a>1.2.2 default boxes定义</h3><p>再等一下…</p>
<p>我们说<code>SSD</code>其实也是有基于anchor box思想的，也就是说，我们会预先给每个输出的框预定义一个应该的大小和长宽比，模型实际输出的中心位置、长、宽等这些数据都是基于这些预定义框的，即default box，所以我们需要去先定义这些default boxes，具体的参见论文2.2小节<code>Choosing scales and aspect ratios</code>的描述,思想大概是这样的：</p>
<p>我们知道，SSD在网络的不同层都会输出一定量的box，例如VGG的Conv4_3层，Extra中的一些层，越靠前越有可能检测出一些小的物体，而越靠后就越可能检测出高层次语义的物体，也即大物体。于是作者给每个feature maps定义了一个scale，也就是default box的大小，各个feature maps的scale计算方法如下：</p>
<p><img src="scale.jpg" alt=""></p>
<p>即最开始的层的scale是0.2，最后面的是0.9，中间依次递增，哦，这个scale是default box相对于整个图片的比例（也就是SSD-300中的输入尺寸300）。</p>
<p>大小定义完了，我们还要定义default box的长宽比，比如说，一辆车子更有可能是<code>width&gt;height</code>，而一个人的话就更有可能是<code>width&lt;height</code>的情况。当然，你肯定也有不符合这种“常规”的物体，比如说。。胖子，那他的长宽比可能就是<code>width=height</code>。。。我不是故意黑胖子，这里只是调侃一下，于是作者为每种大小的default box又定义了几个aspect ratio，即<code>a_r∈{1,2,3,1/2,1/3}</code>，于是<code>Width=S_k * sqrt(a_r), Height=Width=S_k / sqrt(a_r)</code>,这里的S<em>k就是每种default box的大小，即上述的scale。在aspect ratio为1的时候，作者还新增了一种scale，`S_k’=sqrt(s_k , s</em>{k+1} )`</p>
<p>这些框的scale和aspect ratio都定义完了后，我们到时候让模型输出数据的是<code>基于一种中心位置的定位方式</code>，这是我自己给这种定位方式取的名字，反正明白啥意思就行，就是说，到时候每个输出框会依次输出4个数据<code>（框中心的x坐标，框中心的y坐标，框的宽相对于整个图片的比例，框的高相对于整个图片的比例）</code>。</p>
<p>而还有一种定位方式，不妨称之为<code>基于左上角和右下角坐标的表述方式</code>，也就是PASCAL VOC 数据集的标注格式，关于这个数据集的一些信息介绍，可以看我之前记的一篇文章<a href="https://liuzhian.github.io/2019/11/17/PASCAL%20VOC%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/">PASCAL VOC数据集介绍</a>,即：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;bndbox&gt;</span><br><span class="line">    &lt;xmin&gt;3&lt;/xmin&gt;</span><br><span class="line">    &lt;ymin&gt;304&lt;/ymin&gt;</span><br><span class="line">    &lt;xmax&gt;500&lt;/xmax&gt;</span><br><span class="line">    &lt;ymax&gt;375&lt;/ymax&gt;</span><br><span class="line">&lt;/bndbox&gt;</span><br></pre></td></tr></table></figure><br>OK,说了这么多，看下代码就非常清晰了，代码可能和我上述的讲解有那么一丢丢不一样，整体思路是完全没问题的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt <span class="keyword">as</span> sqrt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> product <span class="keyword">as</span> product</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PriorBox</span><span class="params">(object)</span>:</span></span><br><span class="line">	<span class="string">"""Compute priorbox coordinates in center-offset form for each source</span></span><br><span class="line"><span class="string">	feature map.</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, cfg)</span>:</span></span><br><span class="line">		super(PriorBox, self).__init__()</span><br><span class="line">		self.image_size = cfg[<span class="string">'min_dim'</span>]</span><br><span class="line">		<span class="comment"># number of priors for feature map location (either 4 or 6)</span></span><br><span class="line">		self.num_priors = len(cfg[<span class="string">'aspect_ratios'</span>])</span><br><span class="line">		self.variance = cfg[<span class="string">'variance'</span>] <span class="keyword">or</span> [<span class="number">0.1</span>]</span><br><span class="line">		self.feature_maps = cfg[<span class="string">'feature_maps'</span>]</span><br><span class="line">		self.min_sizes = cfg[<span class="string">'min_sizes'</span>]</span><br><span class="line">		self.max_sizes = cfg[<span class="string">'max_sizes'</span>]</span><br><span class="line">		self.steps = cfg[<span class="string">'steps'</span>]</span><br><span class="line">		self.aspect_ratios = cfg[<span class="string">'aspect_ratios'</span>]</span><br><span class="line">		self.clip = cfg[<span class="string">'clip'</span>]</span><br><span class="line">		self.version = cfg[<span class="string">'name'</span>]</span><br><span class="line">		<span class="keyword">for</span> v <span class="keyword">in</span> self.variance:</span><br><span class="line">			<span class="keyword">if</span> v &lt;= <span class="number">0</span>:</span><br><span class="line">				<span class="keyword">raise</span> ValueError(<span class="string">'Variances must be greater than 0'</span>)</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">		mean = []</span><br><span class="line">		<span class="keyword">for</span> k, f <span class="keyword">in</span> enumerate(self.feature_maps):  <span class="comment"># 存放的是feature map的尺寸:38,19,10,5,3,1</span></span><br><span class="line">			<span class="comment"># steps=[8,16,32,64,100,300]. f_k大约为feature map的尺寸</span></span><br><span class="line">			f_k = self.image_size / self.steps[k]</span><br><span class="line"></span><br><span class="line">			<span class="comment"># 求解每个feature map上的每个位置的中心</span></span><br><span class="line">			<span class="keyword">for</span> i, j <span class="keyword">in</span> product(range(f), repeat=<span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">				<span class="comment"># unit center x,y</span></span><br><span class="line">				cx = (j + <span class="number">0.5</span>) / f_k</span><br><span class="line">				cy = (i + <span class="number">0.5</span>) / f_k</span><br><span class="line"></span><br><span class="line">				<span class="comment"># aspect_ratio: 1</span></span><br><span class="line">				<span class="comment"># rel size: min_size</span></span><br><span class="line">				s_k = self.min_sizes[k] / self.image_size</span><br><span class="line">				mean += [cx, cy, s_k, s_k]</span><br><span class="line">				<span class="comment"># aspect_ratio: 1</span></span><br><span class="line">				<span class="comment"># rel size: sqrt(s_k * s_(k+1))</span></span><br><span class="line">				s_k_prime = sqrt(s_k * (self.max_sizes[k] / self.image_size))</span><br><span class="line">				mean += [cx, cy, s_k_prime, s_k_prime]</span><br><span class="line"></span><br><span class="line">				<span class="comment"># rest of aspect ratios</span></span><br><span class="line">				<span class="keyword">for</span> ar <span class="keyword">in</span> self.aspect_ratios[k]:</span><br><span class="line">					mean += [cx, cy, s_k * sqrt(ar), s_k / sqrt(ar)]</span><br><span class="line">					mean += [cx, cy, s_k / sqrt(ar), s_k * sqrt(ar)]</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 执行完上述操作后，总共有 38*38*4 + 19*19*6 + 10*10*6 + 5*5*6 + 3*3*4 + 1*1*4 = 8732个default box</span></span><br><span class="line">		<span class="comment"># back to torch land</span></span><br><span class="line">		output = torch.Tensor(mean).view(<span class="number">-1</span>, <span class="number">4</span>)</span><br><span class="line">		<span class="comment"># print(output[5772:5776])</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># 将输入input张量每个元素的夹紧到区间 [min,max]之内</span></span><br><span class="line">		<span class="keyword">if</span> self.clip:</span><br><span class="line">			output.clamp_(max=<span class="number">1</span>, min=<span class="number">0</span>)</span><br><span class="line">		<span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="1-2-2-训练"><a href="#1-2-2-训练" class="headerlink" title="1.2.2 训练"></a>1.2.2 训练</h3><p>终于可以开始训练了，接着上述代码流程，如果是resume的话，直接载入SSD-300的各种权重参数，如果是第一次训练的话，只有SSD的VGG部分会载入pre-trained的权重，地址是<a href="https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth" target="_blank" rel="noopener">https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth</a>。此外，还要初始化extra部分、loc部分、conf部分的参数，权重初始化方式用的是<code>xavier</code> 方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,</span><br><span class="line">                          weight_decay=args.weight_decay)</span><br><span class="line">    criterion = MultiBoxLoss(cfg[<span class="string">'num_classes'</span>], <span class="number">0.5</span>, <span class="literal">True</span>, <span class="number">0</span>, <span class="literal">True</span>, <span class="number">3</span>, <span class="number">0.5</span>,</span><br><span class="line">                             <span class="literal">False</span>, args.cuda)</span><br></pre></td></tr></table></figure><br>从这里可以看到，loss function是自定义的MultiBoxLoss模块，它在<code>modules/multibox_loss.py</code>文件中被如下定义：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> data <span class="keyword">import</span> coco <span class="keyword">as</span> cfg</span><br><span class="line"><span class="keyword">from</span> ..box_utils <span class="keyword">import</span> match, log_sum_exp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiBoxLoss</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">	<span class="string">"""SSD Weighted Loss Function</span></span><br><span class="line"><span class="string">	Compute Targets:</span></span><br><span class="line"><span class="string">		1) Produce Confidence Target Indices by matching  ground truth boxes</span></span><br><span class="line"><span class="string">		   with (default) 'priorboxes' that have jaccard index &gt; threshold parameter</span></span><br><span class="line"><span class="string">		   (default threshold: 0.5).</span></span><br><span class="line"><span class="string">		2) Produce localization target by 'encoding' variance into offsets of ground</span></span><br><span class="line"><span class="string">		   truth boxes and their matched  'priorboxes'.</span></span><br><span class="line"><span class="string">		3) Hard negative mining to filter the excessive number of negative examples</span></span><br><span class="line"><span class="string">		   that comes with using a large number of default bounding boxes.</span></span><br><span class="line"><span class="string">		   (default negative:positive ratio 3:1)</span></span><br><span class="line"><span class="string">	Objective Loss:</span></span><br><span class="line"><span class="string">		L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N</span></span><br><span class="line"><span class="string">		Where, Lconf is the CrossEntropy Loss and Lloc is the SmoothL1 Loss</span></span><br><span class="line"><span class="string">		weighted by α which is set to 1 by cross val.</span></span><br><span class="line"><span class="string">		Args:</span></span><br><span class="line"><span class="string">			c: class confidences,</span></span><br><span class="line"><span class="string">			l: predicted boxes,</span></span><br><span class="line"><span class="string">			g: ground truth boxes</span></span><br><span class="line"><span class="string">			N: number of matched default boxes</span></span><br><span class="line"><span class="string">		See: https://arxiv.org/pdf/1512.02325.pdf for more details.</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes, overlap_thresh, prior_for_matching,</span></span></span><br><span class="line"><span class="function"><span class="params">				 bkg_label, neg_mining, neg_pos, neg_overlap, encode_target,</span></span></span><br><span class="line"><span class="function"><span class="params">				 use_gpu=True)</span>:</span></span><br><span class="line">		super(MultiBoxLoss, self).__init__()</span><br><span class="line">		self.use_gpu = use_gpu</span><br><span class="line">		self.num_classes = num_classes</span><br><span class="line">		self.threshold = overlap_thresh  <span class="comment"># iou阈值</span></span><br><span class="line">		self.background_label = bkg_label  <span class="comment"># 背景标签 0</span></span><br><span class="line">		self.encode_target = encode_target</span><br><span class="line">		self.use_prior_for_matching = prior_for_matching</span><br><span class="line">		self.do_neg_mining = neg_mining</span><br><span class="line">		self.negpos_ratio = neg_pos  <span class="comment"># 负正样例比</span></span><br><span class="line">		self.neg_overlap = neg_overlap  <span class="comment"># 负样本阈值 没用到</span></span><br><span class="line">		self.variance = cfg[<span class="string">'variance'</span>]</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, predictions, targets)</span>:</span></span><br><span class="line">		<span class="string">"""Multibox Loss</span></span><br><span class="line"><span class="string">		Args:</span></span><br><span class="line"><span class="string">			predictions (tuple): A tuple containing loc preds, conf preds,</span></span><br><span class="line"><span class="string">			and prior boxes from SSD net.</span></span><br><span class="line"><span class="string">				conf shape: torch.size(batch_size,num_priors,num_classes)</span></span><br><span class="line"><span class="string">				loc shape: torch.size(batch_size,num_priors,4)</span></span><br><span class="line"><span class="string">				priors shape: torch.size(num_priors,4)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">			targets (tensor): Ground truth boxes and labels for a batch,</span></span><br><span class="line"><span class="string">				shape: [batch_size,num_objs,5] (last idx is the label).</span></span><br><span class="line"><span class="string">		"""</span></span><br><span class="line">		<span class="comment"># loc_data [batch, 8732, 4]</span></span><br><span class="line">		<span class="comment"># conf_data [batch, 8732, 21]</span></span><br><span class="line">		<span class="comment"># priors  [8732, 4]</span></span><br><span class="line">		loc_data, conf_data, priors = predictions</span><br><span class="line">		num = loc_data.size(<span class="number">0</span>)</span><br><span class="line">		priors = priors[:loc_data.size(<span class="number">1</span>), :]  <span class="comment"># 维度不变</span></span><br><span class="line">		num_priors = (priors.size(<span class="number">0</span>))  <span class="comment"># 8732</span></span><br><span class="line">		num_classes = self.num_classes  <span class="comment"># 21</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># match priors (default boxes) and ground truth boxes</span></span><br><span class="line">		loc_t = torch.Tensor(num, num_priors, <span class="number">4</span>)</span><br><span class="line">		conf_t = torch.LongTensor(num, num_priors)</span><br><span class="line">		<span class="keyword">for</span> idx <span class="keyword">in</span> range(num):</span><br><span class="line">			<span class="comment"># target shape  [batch_size,num_objs,5]</span></span><br><span class="line">			truths = targets[idx][:, :<span class="number">-1</span>].data  <span class="comment"># [num_objs,4],即坐标位置</span></span><br><span class="line">			labels = targets[idx][:, <span class="number">-1</span>].data  <span class="comment"># 最后一维是类别的label,因为用的是-1，不是-1:,所以返回的shape是 [num_objs]</span></span><br><span class="line">			defaults = priors.data</span><br><span class="line"></span><br><span class="line">			<span class="comment"># ！！！关键函数！！！ default box和gt box之前的匹配</span></span><br><span class="line">			<span class="comment">#</span></span><br><span class="line">			<span class="comment"># 这里输入的defaults是基于中心表示的，输入的truths是基于左上角和右下角坐标表示的，在match函数中会有相应的处理</span></span><br><span class="line">			<span class="comment">#</span></span><br><span class="line">			<span class="comment"># 最后两个个参数loc_t, conf_t 其实是输出参数，</span></span><br><span class="line">			<span class="comment"># loc_t在调用后，返回的是第idx图片张输入时，各个default box 匹配到的gt box，相对于default box的偏移量</span></span><br><span class="line">			<span class="comment"># conf_t在调用后，返回的是第idx张图片输入时，各个default box匹配到的gt box的类别label值。</span></span><br><span class="line">			<span class="comment"># 注意，不一定所有的default box都有label, 例如有的default box 和 匹配到的gt box overlap太低，就被视作了背景</span></span><br><span class="line">			match(self.threshold, truths, defaults, self.variance, labels,</span><br><span class="line">				  loc_t, conf_t, idx)</span><br><span class="line">		<span class="keyword">if</span> self.use_gpu:</span><br><span class="line">			loc_t = loc_t.cuda()</span><br><span class="line">			conf_t = conf_t.cuda()</span><br><span class="line">		<span class="comment"># wrap targets</span></span><br><span class="line">		<span class="comment"># # 用Variable封装loc_t, 新版本的 PyTorch 无需这么做, 只需要将 requires_grad 属性设置为 True 就行了</span></span><br><span class="line">		<span class="comment"># loc_t: shape [batch,num_priors,4] encoded offsets to learn</span></span><br><span class="line">		<span class="comment"># conf_t: shape [batch,num_priors] top class label for each prior</span></span><br><span class="line">		loc_t = Variable(loc_t, requires_grad=<span class="literal">False</span>)</span><br><span class="line">		conf_t = Variable(conf_t, requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 筛选出那些 label不是0的default box.类型为bool pos: shape[batch,num_priors]</span></span><br><span class="line">		pos = conf_t &gt; <span class="number">0</span>  <span class="comment"># 即正样本下标</span></span><br><span class="line">		<span class="comment"># 统计label不是0的default box数量， 所有的default box数量为8732 [batch,1]</span></span><br><span class="line">		num_pos = pos.sum(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Localization Loss (Smooth L1)</span></span><br><span class="line">		<span class="comment"># Shape: [batch,num_priors,4]</span></span><br><span class="line">		<span class="comment"># pos_idx: [batch, num_priors, 4]，这里的pos_idx作用就是论文（2）式中的X_&#123;i,j&#125;^&#123;p&#125;</span></span><br><span class="line">		pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)</span><br><span class="line">		loc_p = loc_data[pos_idx].view(<span class="number">-1</span>, <span class="number">4</span>)  <span class="comment"># 预测的offset</span></span><br><span class="line">		loc_t = loc_t[pos_idx].view(<span class="number">-1</span>, <span class="number">4</span>)  <span class="comment"># 匹配的gt的offset</span></span><br><span class="line">		<span class="comment"># smooth-L1 loss</span></span><br><span class="line">		loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Compute max conf across batch for hard negative mining</span></span><br><span class="line">		<span class="comment"># 计算最大置信度，以进行难负样本挖掘</span></span><br><span class="line">		<span class="comment"># conf_data: [batch,num_priors,num_classes]</span></span><br><span class="line">		batch_conf = conf_data.view(<span class="number">-1</span>, self.num_classes)  <span class="comment"># batch_conf: [batch * num_priors,num_classes]</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># batch_conf.gather(1, conf_t.view(-1, 1)) 返回的是每个default box 真实label 对应的预测置信度</span></span><br><span class="line">		<span class="comment"># batch_conf.gather(1, conf_t.view(-1, 1)) shape 为 [batch*num_priors,1]</span></span><br><span class="line">		<span class="comment"># 下式求的是论文（3）式</span></span><br><span class="line">		loss_c = log_sum_exp(batch_conf) - batch_conf.gather(<span class="number">1</span>, conf_t.view(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Hard Negative Mining</span></span><br><span class="line">		<span class="comment"># 难负样本挖掘, 按照loss进行排序, 取loss最大的负样本参与更新</span></span><br><span class="line">		<span class="comment"># loss_c shape 为[batch*num_priors,1]</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># 先让那些正样本，也就是default box 对应的 gt lable 不是背景的样本，先设置为0</span></span><br><span class="line">		loss_c[pos] = <span class="number">0</span>  <span class="comment"># filter out pos boxes for now</span></span><br><span class="line">		<span class="comment"># loss_c 还原回到 [batch, num_priors]</span></span><br><span class="line">		loss_c = loss_c.view(num, <span class="number">-1</span>)</span><br><span class="line">		<span class="comment"># 对loss_c的下标进行降序排序，得到排序后的下标</span></span><br><span class="line">		<span class="comment"># 因为我们在前面将正样本的loss_c置为了0，所以排在前面的都是那些负样本的loss_c</span></span><br><span class="line">		_, loss_idx = loss_c.sort(<span class="number">1</span>, descending=<span class="literal">True</span>)</span><br><span class="line">		<span class="comment"># 对下标进行排序，得到下标的下标 ，shape 为[batch,num_priors]</span></span><br><span class="line">		_, idx_rank = loss_idx.sort(<span class="number">1</span>)</span><br><span class="line">		<span class="comment"># pos的shape是[batch,num_priors]， num_pos统计的是每个样本的正样本数目，也就是obj的数量,shape 为[batch,1]</span></span><br><span class="line">		num_pos = pos.long().sum(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">		<span class="comment"># 根据正样本的数量，确定负样本的数量</span></span><br><span class="line">		num_neg = torch.clamp(self.negpos_ratio * num_pos, max=pos.size(<span class="number">1</span>) - <span class="number">1</span>)</span><br><span class="line">		<span class="comment"># 获取到负样本的下标类型为bool，shape[batch,num_priors]</span></span><br><span class="line">		neg = idx_rank &lt; num_neg.expand_as(idx_rank)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Confidence Loss Including Positive and Negative Examples</span></span><br><span class="line">		<span class="comment"># conf_data的shape是[batch,num_priors,num_classes]</span></span><br><span class="line">		<span class="comment"># pos的shape是 [batch,num_priors],类型为bool，标定某个defaul box是否是正样本</span></span><br><span class="line">		<span class="comment"># pos_idx 的shape扩张后变为 [batch,num_priors，num_classes]，也是bool类型</span></span><br><span class="line">		pos_idx = pos.unsqueeze(<span class="number">2</span>).expand_as(conf_data)</span><br><span class="line">		<span class="comment"># neg 同理 pos</span></span><br><span class="line">		neg_idx = neg.unsqueeze(<span class="number">2</span>).expand_as(conf_data)</span><br><span class="line">		<span class="comment"># 只要样本是正样本或者负样本，就选出来，准备算到总的loss里面</span></span><br><span class="line">		<span class="comment"># conf_p的shape 是 [batch*num_priors,num_classes]</span></span><br><span class="line">		conf_p = conf_data[(pos_idx + neg_idx).gt(<span class="number">0</span>)].view(<span class="number">-1</span>, self.num_classes)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 只要是正或者负样本，就取出来，targets_weighted表示它的真实标签</span></span><br><span class="line">		<span class="comment"># targets_weighted 的shape为[batch,num_priors]</span></span><br><span class="line">		targets_weighted = conf_t[(pos + neg).gt(<span class="number">0</span>)]</span><br><span class="line">		loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Sum of losses: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N</span></span><br><span class="line"></span><br><span class="line">		N = num_pos.data.sum()</span><br><span class="line">		loss_l /= N</span><br><span class="line">		loss_c /= N</span><br><span class="line">		<span class="keyword">return</span> loss_l, loss_c</span><br></pre></td></tr></table></figure><br>其实我觉得这就是最关键、也是比较难一下子搞懂的地方。就说几个比较重要的部分：</p>
<ul>
<li>先从<code>forward()</code>函数开始，一直到第86行，有个<code>match()</code>函数，也就是把default box和ground-truth的框给匹配起来的函数。在论文的<code>Matching Startegy</code>部分有说道，不仅要匹配每个ground truth box对应的default box，同样也要匹配那些与ground turth box交并比大于0.5的default box.<br>什么意思呢？我的理解就是，假如我们只匹配每个ground truth box对应的default box，然后只根据这些default box和预测的box求loss，再反向传播求梯度，更新参数。。balabala的，就会迫使模型去输出更少但是更精确的框（也即迫使模型去学习一种能力，什么能力呢？选择输出最佳的能力）；而如果我们也匹配那些与ground turth box交并比大于0.5的default box，把这些default box和预测的box之间的loss也加入到最终的损失中去，到时候模型发现一旦有物体与ground truth box的overlap大于0.5，我就把它输出（当然，这里可能不精确，但是输出框框的数目更多了，到时候用non-max suppersion给它筛选一下就可以了）。千言万语说了这么多，其实就是论文中段话的意思：</li>
</ul>
<blockquote>
<p>We begin by matching each ground truth box to the default box with the best jaccard overlap (as in MultiBox [7]). Unlike MultiBox, we then match default boxes to any ground truth with jaccard overlap higher than a threshold (0.5). This simplifies the learning problem, allowing the network to predict high scores for multiple overlapping default boxes rather than requiring it to pick only the one with maximum overlap.</p>
</blockquote>
<p>下面是<code>match()</code>函数，我加了一些注释：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match</span><span class="params">(threshold, truths, priors, variances, labels, loc_t, conf_t, idx)</span>:</span></span><br><span class="line">	<span class="string">"""Match each prior box with the ground truth box of the highest jaccard</span></span><br><span class="line"><span class="string">	overlap, encode the bounding boxes, then return the matched indices</span></span><br><span class="line"><span class="string">	corresponding to both confidence and location preds.</span></span><br><span class="line"><span class="string">	Args:</span></span><br><span class="line"><span class="string">		threshold: (float) The overlap threshold used when mathing boxes.</span></span><br><span class="line"><span class="string">		truths: (tensor) Ground truth boxes, Shape: [num_obj, 4].</span></span><br><span class="line"><span class="string">		priors: (tensor) Prior boxes from priorbox layers, Shape: [n_priors,4].</span></span><br><span class="line"><span class="string">		variances: (tensor) Variances corresponding to each prior coord,</span></span><br><span class="line"><span class="string">			Shape: [num_priors, 4].</span></span><br><span class="line"><span class="string">		labels: (tensor) All the class labels for the image, Shape: [num_obj].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">		loc_t: (tensor) Tensor to be filled w/ endcoded location targets.</span></span><br><span class="line"><span class="string">		conf_t: (tensor) Tensor to be filled w/ matched indices for conf preds.</span></span><br><span class="line"><span class="string">		idx: (int) current batch index</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	Return:</span></span><br><span class="line"><span class="string">		The matched indices corresponding to 1)location and 2)confidence preds.</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="comment"># jaccard index , shape [num_objects,n_priors]</span></span><br><span class="line">	overlaps = jaccard(</span><br><span class="line">		truths,</span><br><span class="line">		point_form(priors)</span><br><span class="line">	)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 在论文的Matching Strategy说到，不仅对每个GT box,去match最匹配的default box，也对每个default box，去match最匹配的GT-box</span></span><br><span class="line">	<span class="comment"># 这样一来，可以让网络预测出更多的overlapping的default box，而不要让网络去选择一个最好的，至于最后怎么选择，用non-max suppression即可。</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># (Bipartite Matching)</span></span><br><span class="line">	<span class="comment"># [num_objects，1]</span></span><br><span class="line">	<span class="comment"># 表示和每个GT box重叠得最好的那个default box</span></span><br><span class="line">	best_prior_overlap, best_prior_idx = overlaps.max(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">	<span class="comment"># [1,num_priors]</span></span><br><span class="line">	<span class="comment"># 表示和每个default box重叠得最好的那个GT box</span></span><br><span class="line">	best_truth_overlap, best_truth_idx = overlaps.max(<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># shape [num_objects]</span></span><br><span class="line">	best_truth_idx.squeeze_(<span class="number">0</span>)</span><br><span class="line">	best_truth_overlap.squeeze_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># shape [num_prior]</span></span><br><span class="line">	best_prior_idx.squeeze_(<span class="number">1</span>)</span><br><span class="line">	best_prior_overlap.squeeze_(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 该语句会将与gt box匹配度最好的prior box 的交并比置为 2, 确保其最大, 以免防止某些 gtbox 没有匹配的 priorbox.</span></span><br><span class="line">	best_truth_overlap.index_fill_(<span class="number">0</span>, best_prior_idx, <span class="number">2</span>)  <span class="comment"># ensure best prior</span></span><br><span class="line">	<span class="comment"># TODO refactor: index  best_prior_idx with long tensor</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># ensure every gt matches with its prior of max overlap</span></span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> range(best_prior_idx.size(<span class="number">0</span>)):</span><br><span class="line">		best_truth_idx[best_prior_idx[j]] = j</span><br><span class="line"></span><br><span class="line">	<span class="comment"># best_truth_idx表示的是每个default box 对应的最佳匹配的 gt box下标，下标元素的取值范围是 0~(num_objs-1)</span></span><br><span class="line">	<span class="comment"># 元素的个数，也就是len(best_truth_idx)=num_priors, 也就是defalut box的个数。</span></span><br><span class="line">	<span class="comment">#</span></span><br><span class="line">	<span class="comment"># truth又是一个shape为[num_objs,4]的tensor，表示的是这么多个objs的box</span></span><br><span class="line">	<span class="comment">#</span></span><br><span class="line">	<span class="comment"># 所以truths[best_truth_idx] 代表的就是 每个default box 对应的最匹配的 gt box</span></span><br><span class="line">	matches = truths[best_truth_idx]  <span class="comment"># Shape: [num_priors,4]</span></span><br><span class="line">	<span class="comment"># conf是每个default box对应最匹配的gt box的类别，记住，0代表背景</span></span><br><span class="line">	conf = labels[best_truth_idx] + <span class="number">1</span>  <span class="comment"># Shape: [num_priors]</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 对于每个default box，如果它与某个gt box的overlap小于阈值，那么就将这个default box的类别设置为0，即背景</span></span><br><span class="line">	conf[best_truth_overlap &lt; threshold] = <span class="number">0</span>  <span class="comment"># label as background</span></span><br><span class="line">	<span class="string">""" 把每个defalut box 匹配到的 gt box转化为 中心坐标的形式 """</span></span><br><span class="line">	loc = encode(matches, priors, variances)</span><br><span class="line">	loc_t[idx] = loc  <span class="comment"># [num_priors,4] encoded offsets to learn</span></span><br><span class="line">	conf_t[idx] = conf  <span class="comment"># [num_priors] top class label for each prior</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>还有就是Hard negative mining部分，中文是难样本挖掘，反正翻译起来很怪就对了，无所谓了。意思就是，我们知道SSD中会有大量的default box（8732个）,这其中有绝大部分都是背景，只有很少一部分是object。即positive的样本数会远少于negative样本数。为了不让模型过度的学习negative信息，我们对所有负样本的置信度进行排序，只选择置信度较高的一部分负样本，使得负样本和正样本的比例是3:1，也就是<code>MultiBoxLoss类</code>代码中112-156行的部分。</li>
</ul>
<h3 id="1-2-3-测试"><a href="#1-2-3-测试" class="headerlink" title="1.2.3 测试"></a>1.2.3 测试</h3><p>测试代码，主要就是加载预训练的模型，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> data <span class="keyword">import</span> VOC_ROOT, VOC_CLASSES <span class="keyword">as</span> labelmap</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> data <span class="keyword">import</span> VOCAnnotationTransform, VOCDetection, BaseTransform, VOC_CLASSES</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">from</span> ssd <span class="keyword">import</span> build_ssd</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Single Shot MultiBox Detection'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--trained_model'</span>, default=<span class="string">'weights/ssd_300_VOC0712.pth'</span>,</span><br><span class="line">                    type=str, help=<span class="string">'Trained state_dict file path to open'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--save_folder'</span>, default=<span class="string">'eval/'</span>, type=str,</span><br><span class="line">                    help=<span class="string">'Dir to save results'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--visual_threshold'</span>, default=<span class="number">0.6</span>, type=float,</span><br><span class="line">                    help=<span class="string">'Final confidence threshold'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--cuda'</span>, default=<span class="literal">True</span>, type=bool,</span><br><span class="line">                    help=<span class="string">'Use cuda to train model'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--voc_root'</span>, default=VOC_ROOT, help=<span class="string">'Location of VOC root directory'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, default=<span class="literal">None</span>, type=str, help=<span class="string">"Dummy arg so we can load in Jupyter Notebooks"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.cuda <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">    torch.set_default_tensor_type(<span class="string">'torch.cuda.FloatTensor'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    torch.set_default_tensor_type(<span class="string">'torch.FloatTensor'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.save_folder):</span><br><span class="line">    os.mkdir(args.save_folder)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_net</span><span class="params">(save_folder, net, cuda, testset, transform, thresh)</span>:</span></span><br><span class="line">    <span class="comment"># dump predictions and assoc. ground truth to text file for now</span></span><br><span class="line">    filename = save_folder+<span class="string">'test1.txt'</span></span><br><span class="line">    num_images = len(testset)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_images):</span><br><span class="line">        print(<span class="string">'Testing image &#123;:d&#125;/&#123;:d&#125;....'</span>.format(i+<span class="number">1</span>, num_images))</span><br><span class="line">        img = testset.pull_image(i)</span><br><span class="line">        img_id, annotation = testset.pull_anno(i)</span><br><span class="line">        x = torch.from_numpy(transform(img)[<span class="number">0</span>]).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        x = Variable(x.unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(filename, mode=<span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">'\nGROUND TRUTH FOR: '</span>+img_id+<span class="string">'\n'</span>)</span><br><span class="line">            <span class="keyword">for</span> box <span class="keyword">in</span> annotation:</span><br><span class="line">                f.write(<span class="string">'label: '</span>+<span class="string">' || '</span>.join(str(b) <span class="keyword">for</span> b <span class="keyword">in</span> box)+<span class="string">'\n'</span>)</span><br><span class="line">        <span class="keyword">if</span> cuda:</span><br><span class="line">            x = x.cuda()</span><br><span class="line"></span><br><span class="line">        y = net(x)      <span class="comment"># forward pass</span></span><br><span class="line">        detections = y.data</span><br><span class="line">        <span class="comment"># scale each detection back up to the image</span></span><br><span class="line">        scale = torch.Tensor([img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>],</span><br><span class="line">                             img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]])</span><br><span class="line">        pred_num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(detections.size(<span class="number">1</span>)):</span><br><span class="line">            j = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> detections[<span class="number">0</span>, i, j, <span class="number">0</span>] &gt;= <span class="number">0.6</span>:</span><br><span class="line">                <span class="keyword">if</span> pred_num == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">with</span> open(filename, mode=<span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        f.write(<span class="string">'PREDICTIONS: '</span>+<span class="string">'\n'</span>)</span><br><span class="line">                score = detections[<span class="number">0</span>, i, j, <span class="number">0</span>]</span><br><span class="line">                label_name = labelmap[i<span class="number">-1</span>]</span><br><span class="line">                pt = (detections[<span class="number">0</span>, i, j, <span class="number">1</span>:]*scale).cpu().numpy()</span><br><span class="line">                coords = (pt[<span class="number">0</span>], pt[<span class="number">1</span>], pt[<span class="number">2</span>], pt[<span class="number">3</span>])</span><br><span class="line">                pred_num += <span class="number">1</span></span><br><span class="line">                <span class="keyword">with</span> open(filename, mode=<span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.write(str(pred_num)+<span class="string">' label: '</span>+label_name+<span class="string">' score: '</span> +</span><br><span class="line">                            str(score) + <span class="string">' '</span>+<span class="string">' || '</span>.join(str(c) <span class="keyword">for</span> c <span class="keyword">in</span> coords) + <span class="string">'\n'</span>)</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_voc</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># load net</span></span><br><span class="line">    num_classes = len(VOC_CLASSES) + <span class="number">1</span> <span class="comment"># +1 background</span></span><br><span class="line">    net = build_ssd(<span class="string">'test'</span>, <span class="number">300</span>, num_classes) <span class="comment"># initialize SSD</span></span><br><span class="line">    net.load_state_dict(torch.load(args.trained_model))</span><br><span class="line">    net.eval()  <span class="comment"># 设置是eval()模式，所以不会更新参数</span></span><br><span class="line">    print(<span class="string">'Finished loading model!'</span>)</span><br><span class="line">    <span class="comment"># load data</span></span><br><span class="line">    testset = VOCDetection(args.voc_root, [(<span class="string">'2007'</span>, <span class="string">'test'</span>)], <span class="literal">None</span>, VOCAnnotationTransform())</span><br><span class="line">    <span class="keyword">if</span> args.cuda:</span><br><span class="line">        net = net.cuda()</span><br><span class="line">        cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># evaluation</span></span><br><span class="line">    test_net(args.save_folder, net, args.cuda, testset,</span><br><span class="line">             BaseTransform(net.size, (<span class="number">104</span>, <span class="number">117</span>, <span class="number">123</span>)),</span><br><span class="line">             thresh=args.visual_threshold)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    test_voc()</span><br></pre></td></tr></table></figure></p>
<h1 id="2-遇到的问题"><a href="#2-遇到的问题" class="headerlink" title="2.遇到的问题"></a>2.遇到的问题</h1><h2 id="2-1-维度不匹配"><a href="#2-1-维度不匹配" class="headerlink" title="2.1 维度不匹配"></a>2.1 维度不匹配</h2><p>即<a href="https://github.com/amdegroot/ssd.pytorch/issues/173" target="_blank" rel="noopener">issue #173</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">File <span class="string">"XXX/SSD/layers/modules/multibox_loss.py"</span>, line <span class="number">127</span>, <span class="keyword">in</span> forward    </span><br><span class="line">    loss_c[pos] = <span class="number">0</span>  <span class="comment"># filter out pos boxes for now</span></span><br><span class="line">IndexError: </span><br><span class="line">    The shape of the mask [<span class="number">32</span>, <span class="number">8732</span>] at index <span class="number">0</span>does <span class="keyword">not</span> match the shape</span><br><span class="line">    of the indexed tensor [<span class="number">279424</span>,<span class="number">1</span>] at index <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>解决方案：先把loss_c和pos矩阵维度对齐，再操作<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss_c 还原回到 [batch, num_priors]</span></span><br><span class="line">loss_c = loss_c.view(num, <span class="number">-1</span>)</span><br><span class="line"><span class="comment"># 先让那些正样本，也就是default box 对应的 gt lable 不是背景的样本，先设置为0</span></span><br><span class="line">loss_c[pos] = <span class="number">0</span>  <span class="comment"># filter out pos boxes for now</span></span><br></pre></td></tr></table></figure><br>此外还要更新<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># issue #173, reference https://github.com/amdegroot/ssd.pytorch/issues/173</span></span><br><span class="line">N = num_pos.data.sum().double()</span><br><span class="line">loss_l=loss_l.double()</span><br><span class="line">loss_c = loss_c.double()</span><br><span class="line">loss_l /= N</span><br><span class="line">loss_c /= N</span><br></pre></td></tr></table></figure></p>
<h2 id="2-2-取0维tensor值出错"><a href="#2-2-取0维tensor值出错" class="headerlink" title="2.2 取0维tensor值出错"></a>2.2 取0维tensor值出错</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">IndexError: invalid index of a <span class="number">0</span>-dim tensor. Use tensor.item() to convert </span><br><span class="line">a <span class="number">0</span>-dim tensor to a Python number</span><br></pre></td></tr></table></figure>
<p>解决方案：按照提示更改即可，把 <code>tensor.data[0]</code> 全部换成 <code>tensor.item()</code></p>
<h2 id="2-3-不需要求导的变量"><a href="#2-3-不需要求导的变量" class="headerlink" title="2.3 不需要求导的变量"></a>2.3 不需要求导的变量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UserWarning: volatile was removed <span class="keyword">and</span> now has no effect. </span><br><span class="line">    Use <span class="keyword">with</span> `torch.no_grad()`: instead</span><br></pre></td></tr></table></figure>
<p>因为网络中有一些参数是不需要更新的，比如default boxes，<br><code>self.priors = Variable(self.priorbox.forward(), volatile=True)</code></p>
<p>解决方案：用包装器上下文，<code>with torch.no_grad()</code>把不需要求导的变量wrap起来，这应该是pytorch的更新,即<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    self.priors = Variable(self.priorbox.forward())</span><br></pre></td></tr></table></figure></p>
<h2 id="2-4-Xavier初始化函数"><a href="#2-4-Xavier初始化函数" class="headerlink" title="2.4 Xavier初始化函数"></a>2.4 Xavier初始化函数</h2><p><code>UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  init.xavier_uniform(param)</code></p>
<p>解决方案：把<code>init.xavier_uniform(param)</code>换成<code>init.xavier_uniform_(param)</code>，多了一个下划线，以后的版本pytorch应该是不推荐这样使用“私有函数“的</p>
<h2 id="2-5-F-smooth-l1-loss"><a href="#2-5-F-smooth-l1-loss" class="headerlink" title="2.5 F.smooth_l1_loss"></a>2.5 F.smooth_l1_loss</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">userwarning: size_average <span class="keyword">and</span> reduce args will be deprecated, </span><br><span class="line">    please use reduction=<span class="string">'sum'</span> instead.</span><br></pre></td></tr></table></figure>
<p>错误出现在multibox_loss.py的<code>loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False)</code>处，因为<code>size_average</code>这个参数已经弃用了，详情见<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.SmoothL1Loss" target="_blank" rel="noopener">Pytorch-API</a>,从官方文档提供的信息我们知道<code>size_average</code>，和<code>reduce</code>这两个参数是有关系的。 </p>
<p>我们先看<code>reduce</code>参数，如果它是<code>false</code>，就直接对每个element都返回对应的loss值，既不求和，也不求平均，是多少就是多少；再看<code>size_average</code>，在<code>reduce=True</code>的前提下，如果<code>size_average=False</code>，就对所有loss求和，如果<code>size_average=True</code>，则对所有的loss求平均。</p>
<p>也就是说，这两个参数之间是有依赖关系的，总的来说，只有3种情况，①只求loss ②对loss求和 ③对loss求平均，所以现在的API已经弃用了前两个参数，请使用reduction参数，reduction有三个取值None, sum, mean分别与上述对应</p>
<p>解决方案：把<code>loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False)</code>改成<code>loss_l = F.smooth_l1_loss(loc_p, loc_t, reduction=&quot;sum&quot;)</code>，同理，在<code>loss_c</code>处也要进行相应修改。</p>
<h2 id="2-6-visdom画图报错"><a href="#2-6-visdom画图报错" class="headerlink" title="2.6 visdom画图报错"></a>2.6 visdom画图报错</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> win <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, <span class="string">'Must define a window to update'</span>,</span><br><span class="line">    AssertionError: Must define a window to update</span><br></pre></td></tr></table></figure>
<p>解决方案：把原代码的<code>epoch+=1</code>行，移到<code>update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None, &#39;append&#39;, epoch_size)</code>前。</p>
<h2 id="2-7-一轮过后取batch报错"><a href="#2-7-一轮过后取batch报错" class="headerlink" title="2.7 一轮过后取batch报错"></a>2.7 一轮过后取batch报错</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">in</span> __next__:<span class="keyword">raise</span> StopIteration  </span><br><span class="line">   StopIteration</span><br></pre></td></tr></table></figure>
<p>问题分析：因为我们会通过<code>batch_iterator = iter(data_loader)</code>来创建一个batch loader,这个lodaer的长度也就是一个epoch中有几个batch (i.e. num_traning_samples/batch_size)，<br>所以当训练了一轮后，batch loader中的数据“用完了”，我们要再次调用 <code>iter(data_loader)</code>来创建一个迭代器。</p>
<p>解决方案：<br>把<code>images, targets = next(batch_iterator)</code>改成，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># issue #214 reference https://github.com/amdegroot/ssd.pytorch/issues/214 </span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    images, targets = next(batch_iterator)</span><br><span class="line"><span class="keyword">except</span> StopIteration:</span><br><span class="line">    batch_iterator = iter(data_loader)</span><br><span class="line">images, targets = next(batch_iterator)</span><br></pre></td></tr></table></figure></p>
<h1 id="3-模型的运用"><a href="#3-模型的运用" class="headerlink" title="3.模型的运用"></a>3.模型的运用</h1><p>如果你发现有任何问题，请在下面评论~</p>


                <hr>

                

                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/2019/11/23/Java多线程核心技术阅读笔记(第六章)/" data-toggle="tooltip" data-placement="top" title="Java多线程核心技术阅读笔记(第六章)">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/2019/11/18/Non-max Suppression非最大抑制/" data-toggle="tooltip" data-placement="top" title="Non-max Suppression非最大抑制">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                

                
				
				
				<!-- 来必力City版安装代码 -->
				<div id="lv-container" data-id="city" data-uid="MTAyMC80NzM2OC8yMzg2OA==" >
					<script type="text/javascript">
				   (function(d, s) {
					   var j, e = d.getElementsByTagName(s)[0];

					   if (typeof LivereTower === 'function') { return; }

					   j = d.createElement(s);
					   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
					   j.async = true;

					   e.parentNode.insertBefore(j, e);
				   })(document, 'script');
					</script>
				<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
				</div>
				<!-- City版安装代码已完成 -->
				

            </div>
    <!-- Side Catalog Container -->
        

    <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#Object Detection" title="Object Detection">Object Detection</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="http://huangxuan.me" target="_blank">Hux Blog</a></li>
                    
                        <li><a href="#" target="_blank">Foo</a></li>
                    
                        <li><a href="#" target="_blank">Bar</a></li>
                    
                </ul>
                
            </div>

        </div>
    </div>
</article>







<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/liu-zhi-an-98">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="http://weibo.com/u/1952886932">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/LiUzHiAn">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; LiuZhian&#39;s Blog 2021 
                    <br>
                    Theme by <a href="http://huangxuan.me" target="_blank" rel="noopener">Hux</a> 
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span> 
                    Ported by <a href="http://blog.kaijun.rocks" target="_blank" rel="noopener">Kaijun</a> | 
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=kaijun&repo=hexo-theme-huxblog&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://liuzhian.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-150994646-1';
    var _gaDomain = '';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->


<!-- Side Catalog -->





<!-- Image to hack wechat -->
<img src="https://liuzhian.github.io/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>

</html>
